{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unlike regressor that predicts the value or an integral value calssifier is used to predict any classical or categorical value that can be interpreted with ir 0 as yes and 1 for no etc ( decision trees can be used for both binary and multiclass calssfication)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important libraries\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "importmatplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependent and independent feature extraction\n",
    "data = pd.read_csv(\"\")\n",
    "x = data.drop[\"target_col_name\"]\n",
    "y = data.target_col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data visualisation and feature importance (extra forest calassifier is the fastest working algo\n",
    "#                                                    which can be used to calculate the best features)\n",
    "rr = ExtraTreeRegressor()\n",
    "rr.fit(xtrain,ytrain)\n",
    "ypr = rr.predict(xtest)\n",
    "print(\"Accuracy score - {} \".format(accuracy_score(ytest,ypr)))\n",
    "print(\"Score(test) - {} \".format(rr.score(xtest,ytest)))\n",
    "print(\"Score(train) - {} \".format(rr.score(xtrain,ytrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the fetureimportance\n",
    "feature = rr.feature_importances_\n",
    "plt.figure(figsize = (16,10))\n",
    "sns.barplot(x = data.columns.drop(\"output\"), y = feature)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a heatmap between corelations (pearson)\n",
    "sns.heatmap(data.corr(),annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a heatmap between corelations (pearson)\n",
    "sns.heatmap(data.corr(),annot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to make a list which can be used to remove or etract the couplets of features which are highly corellated\n",
    "dat = 0 \n",
    "epp = []\n",
    "col = data.columns\n",
    "for i in col:\n",
    "    for j in col:\n",
    "        dat = data[i].corr(data[j])\n",
    "        if dat > 0.4:\n",
    "            epp.append([i,j])\n",
    "print(epp)\n",
    "print(len(epp))\n",
    "\n",
    "\n",
    "# these list aboce will have some common pairs or repeated names so code blow can be used \n",
    "#to extract the final list and we can remoeve these features if we wiah\n",
    "res = []\n",
    "for i in epp:\n",
    "    o = [i[1], i[0]]\n",
    "    if i[0] != i[1] and i  not in res and o not in res :\n",
    "        res.append(i)\n",
    "print(res)\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data visualisation\n",
    "plt.figurre(figsize = (16,9))\n",
    "sns.pairplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scaling and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming data between 0 to 1\n",
    "sc = StandardScaler()\n",
    "sc.fit(x)\n",
    "x= sc.transdorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming data between 0 to 1\n",
    "sc = StandardScaler()\n",
    "sc.fit(x)\n",
    "x= sc.transdorm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(\n",
    "    criterion='gini',                # instead of mse we can use any of {“gini”, “entropy”}\n",
    "    splitter = \"best\",               # instead of best we can also use any of {“best”, “random”}\n",
    "    max_depth=5,                     # can use any integral value i.e. 1,2,3,4,5,6 .......\n",
    "    min_samples_split=4,             # can use any integral value i.e. 1,2,3,4,5,6 .......\n",
    "    max_features = 'auto',           # can use any of  {“auto”, “sqrt”, “log2”}\n",
    "    min_samples_leaf=5            \n",
    "    )\n",
    "dtc.fit(xtrain,ytrain)\n",
    "ypred = dtr.predict(xtest)\n",
    "print(\" score = {}\".format(dtc.score(xtrain,ytrain)))\n",
    "print(\" score = {}\".format(dtc.score(xtest,ytest)))\n",
    "print(\"accuracy score (b/w y test and y pred = {}\".format(accuracy_score(ypred,ytest))\n",
    "print(\"Confusion matrix {}\".format(cofusion_matrix(ytest,ypred)))\n",
    "print(\"Classification Report {}\".format(classification_report(ytest,ypred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.summary() # model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now since we have many different values we can put in thses parameters so we opt for yperparameter tuning using grid search and random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dtr1 = DecisionTreeClassifier()\n",
    "params = {\"criterion\": ['gini','entropy'],\n",
    "          \"splitter\" : ['best', 'random'],\n",
    "          \"max_depth\": [int(x) for x in np.linspace(1,100, 60)],\n",
    "          \"min_sample_leaf\" = [[int(x) for x in np.linspace(1,100, 60)]]\n",
    "         \"min_samples_split\": [0,1,3,5,7,9,11,13,15,17,20,21,25,27,29,33],\n",
    "          \"max_features\" : [\"auto\", \"sqrt\", \"log2\"],\n",
    "         }\n",
    "random = RandomizedSearchCV(estimator = dtr1,param_distributions = params,n_iter = 100,cv = 4,verbose = 3,n_jobs = -1)\n",
    "random.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = random.best_estimator_\n",
    "model.fit(xtrain,ytrain)\n",
    "#now u can predict and find accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "dtr1 = DecisionTreeClassifier()\n",
    "params = {\"criterion\": ['gini','entropy'],\n",
    "          \"splitter\" : ['best', 'random'],\n",
    "          \"max_depth\": [int(x) for x in np.linspace(1,100, 60)],\n",
    "          \"min_sample_leaf\" = [[int(x) for x in np.linspace(1,100, 60)]]\n",
    "         \"min_samples_split\": [0,1,3,5,7,9,11,13,15,17,20,21,25,27,29,33],\n",
    "          \"max_features\" : [\"auto\", \"sqrt\", \"log2\"],\n",
    "         }\n",
    "random = GridSearchCV(estimator = dtr1,param_distributions = params,n_iter = 100,cv = 4,verbose = 3,n_jobs = -1)\n",
    "random.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = random.best_estimator_\n",
    "model1.fit(xtrain,ytrain)\n",
    "#now u can predict and find accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the decision tree and the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "plt.figure(figsize=(15,10))\n",
    "tree.plot_tree(model_name,filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to print the line plot with every feature \n",
    "for i in range(shape(xtest)[1])\n",
    "plt.scatter(xtest[i],ytest)\n",
    "plt.plot(xtest[i],ypred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
